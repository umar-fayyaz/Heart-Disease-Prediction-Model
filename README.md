Iâ€™m excited to share my latest project where I explored the Framingham Heart Disease dataset from Kaggle, a valuable dataset for understanding heart disease risks. This project marks an important milestone in my data science journey, focusing on classification and predictive modeling.â£
â£
ğŸ› ï¸ ğ“ğ¨ğ¨ğ¥ğ¬ & ğ‹ğ¢ğ›ğ«ğšğ«ğ¢ğğ¬ ğ”ğ¬ğğ:â£
For this project, I used several powerful tools and libraries.â£
ğğšğ§ğğšğ¬: For data manipulation and exploration.â£
ğğ®ğ¦ğğ²: For efficient numerical operations.â£
ğŒğšğ­ğ©ğ¥ğ¨ğ­ğ¥ğ¢ğ› & ğ’ğğšğ›ğ¨ğ«ğ§: To visualize data trends, correlations, and outliers.â£
ğ’ğœğ¢ğğ²: Utilized for various statistical functions.â£
ğ’ğœğ¢ğ¤ğ¢ğ­-ğ¥ğğšğ«ğ§: The backbone for implementing machine learning models, data preprocessing, and validation techniques.â£
â£
ğŸ“Š ğƒğšğ­ğš ğğ«ğğ©ğšğ«ğšğ­ğ¢ğ¨ğ§:â£
I began by loading the dataset (a CSV file) and performing basic data exploration to understand its structure. I identified missing values, visualized them, and handled these effectively. Additionally, I checked and removed duplicate entries to ensure data quality, transforming and filtering the data to make it suitable for analysis.â£
â£
ğŸ” ğ„ğ±ğ©ğ¥ğ¨ğ«ğšğ­ğ¨ğ«ğ² ğƒğšğ­ğš ğ€ğ§ğšğ¥ğ²ğ¬ğ¢ğ¬ (ğ„ğƒğ€):â£
In the EDA phase, I conducted a thorough examination using various plots and graphs to uncover insights. This included analyzing correlations between features and the target variable and detecting and addressing outliers to refine the dataset further.â£
â£
ğŸ§  ğŒğšğœğ¡ğ¢ğ§ğ ğ‹ğğšğ«ğ§ğ¢ğ§ğ  ğŒğ¨ğğğ¥ğ¬:â£
ğ‹ğ¨ğ ğ¢ğ¬ğ­ğ¢ğœ ğ‘ğğ ğ«ğğ¬ğ¬ğ¢ğ¨ğ§:â£
Since the dataset was imbalanced, I used SMOTE (Synthetic Minority Over-sampling Technique) to balance it.â£
After splitting the balanced dataset into training and test sets, I applied feature scaling and trained the Logistic Regression model.â£
Accuracy: ~72% on test data, ~71% on training data.â£
Cross-validation using K-Fold resulted in an average accuracy of ~72%.â£
I also analyzed the feature contributions to model performance.â£
â£
ğ—ğ†ğğ¨ğ¨ğ¬ğ­:â£
I explored XGBoost, another powerful classification technique, to compare results.â£
Accuracy: A significant boost with an average of ~84%.â£
Performed cross-validation on XGBoost for further evaluation.â£
â£
ğŸ–¥ï¸ ğˆğ§ğ­ğğ«ğšğœğ­ğ¢ğ¯ğ ğğ«ğğğ¢ğœğ­ğ¢ğ¨ğ§:â£
To make the project more interactive, I developed a simple console input function that predicts heart disease risk based on user inputs. This model provides real-time predictions, making it a practical tool for learning.

This project was an excellent opportunity to strengthen my understanding of classification models and data science workflows. I'm looking forward to further refining my skills and tackling more complex datasets in the future!
